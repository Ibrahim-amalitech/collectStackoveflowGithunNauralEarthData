{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f5435ee",
   "metadata": {},
   "source": [
    "# Scrape Report URLs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771a035e",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4da5ea0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pyodbc\n",
    "from bs4 import BeautifulSoup\n",
    "from sqlalchemy import create_engine,text,String\n",
    "from io import BytesIO\n",
    "import pandas as pd\n",
    "import csv\n",
    "import zipfile\n",
    "import io\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f24311e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "url = 'https://insights.stackoverflow.com/survey'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "current_tags = soup.find_all('div', class_= 'copy-container')\n",
    "target_divs = soup.find_all('div' , class_= 'past-years' )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3e5704",
   "metadata": {},
   "source": [
    "# Grab latest Report Url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b70e32a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For current year\n",
    "current_url = []\n",
    "for current in current_tags:\n",
    "    anchor_element = current.find_all('a')\n",
    "    \n",
    "    for anchor in anchor_element:\n",
    "        href_value = anchor.get(\"href\")\n",
    "        if href_value.endswith(\".zip\"):\n",
    "            current_url.append(href_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2f345122",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://cdn.stackoverflow.co/files/jo7n4k8s/production/49915bfd46d0902c3564fd9a06b509d08a20488c.zip/stack-overflow-developer-survey-2023.zip']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d848c42c",
   "metadata": {},
   "source": [
    "# Getting list of all URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "33aa68d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "urls = []\n",
    "\n",
    "# for previous years\n",
    "\n",
    "for current in current_tags:\n",
    "    anchor_element = current.find_all('a')\n",
    "    \n",
    "    for anchor in anchor_element:\n",
    "        href_value = anchor.get(\"href\")\n",
    "        if href_value.endswith(\".zip\"):\n",
    "            current_url.append(href_value)\n",
    "        else:\n",
    "            \"Check data structure\"\n",
    "\n",
    "# For Previous years\n",
    "# Loop through each target div\n",
    "for target_div in target_divs:\n",
    "    # Find all anchor elements under the target div\n",
    "    anchor_elements = target_div.find_all(\"a\")\n",
    "\n",
    "    # Extract and print href values\n",
    "    for anchor in anchor_elements:\n",
    "        href_value = anchor.get(\"href\")\n",
    "        if href_value.endswith(\".zip\"):\n",
    "            urls.append(href_value)\n",
    "\n",
    "all_urls = current_url + urls\n",
    "\n",
    "# all_urls.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0403a0cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://cdn.stackoverflow.co/files/jo7n4k8s/production/49915bfd46d0902c3564fd9a06b509d08a20488c.zip/stack-overflow-developer-survey-2023.zip'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_urls.pop(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "1f9996a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://cdn.stackoverflow.co/files/jo7n4k8s/production/49915bfd46d0902c3564fd9a06b509d08a20488c.zip/stack-overflow-developer-survey-2023.zip',\n",
       " 'https://info.stackoverflowsolutions.com/rs/719-EMH-566/images/stack-overflow-developer-survey-2022.zip',\n",
       " 'https://info.stackoverflowsolutions.com/rs/719-EMH-566/images/stack-overflow-developer-survey-2021.zip',\n",
       " 'https://info.stackoverflowsolutions.com/rs/719-EMH-566/images/stack-overflow-developer-survey-2020.zip',\n",
       " 'https://info.stackoverflowsolutions.com/rs/719-EMH-566/images/stack-overflow-developer-survey-2019.zip']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_urls=all_urls[0:5]\n",
    "all_urls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5690e7",
   "metadata": {},
   "source": [
    "### Using list iteration of urls to download zip file, unzip and select the required csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "90483527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# downloads zip file\n",
    "zip_downloads = []\n",
    "def download_zip_file(zip_url):\n",
    "    response = requests.get(zip_url)\n",
    "    if response.status_code == 200:\n",
    "        zip_file = response.content\n",
    "        zip_downloads.append(zip_file)\n",
    "        return response.content\n",
    "    else:\n",
    "        return None\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "112c9322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unpacks content of zip file\n",
    "file_names = []\n",
    "def view_zip_contents(zip_data):\n",
    "    with zipfile.ZipFile(BytesIO(zip_data), 'r') as zip_ref:\n",
    "        for file_name in zip_ref.namelist():\n",
    "            file_names.append(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b4927fd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2022'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_characters_before_zip(url):\n",
    "    # Find the position of '.zip' in the URL\n",
    "    zip_index = url.find('.zip')\n",
    "    # Check if '.zip' was found in the URL\n",
    "    if zip_index != -1:\n",
    "        # Extract the 4 characters before '.zip'\n",
    "        four_chars_before_zip = url[zip_index - 4:zip_index]\n",
    "        return four_chars_before_zip\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "extract_characters_before_zip('https://info.stackoverflowsolutions.com/rs/719-EMH-566/images/stack-overflow-developer-survey-2022.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "cd3a1a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract all csv files from unpacked zip folder\n",
    "csv_files = []\n",
    "\n",
    "def extract_csv_from_zip(zip_data, target_csv_name):\n",
    "    csv_data = None\n",
    "    with zipfile.ZipFile(io.BytesIO(zip_data), 'r') as zip_ref:\n",
    "        for file_name in zip_ref.namelist():\n",
    "            if file_name.lower().endswith('.csv') and target_csv_name in file_name:\n",
    "                with zip_ref.open(file_name) as csv_file:\n",
    "                    csv_data = pd.read_csv(csv_file, dtype=str, low_memory=False,encoding='utf-8')\n",
    "                    csv_files.append(csv_data)\n",
    "                break\n",
    "    return csv_data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3b722c70",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Passing list urls and downloaded zip files which were placed in a list\n",
    "for i in range(len(all_urls)):\n",
    "    download_zip_file(all_urls[i])\n",
    "    view_zip_contents(zip_downloads[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d82b26a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['survey_results_public.csv',\n",
       " 'survey_results_public.csv',\n",
       " 'survey_results_public.csv',\n",
       " 'survey_results_public.csv',\n",
       " 'survey_results_public.csv']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove all unwanted files\n",
    "file_names = [ex for ex in file_names if ex.endswith('.csv') and 'MAC' not in ex and 'survey_results_schema'  not in ex and '._' not in ex]\n",
    "file_names = [ f.split('/')[-1] for f in file_names]\n",
    "file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d0e2ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ace1839d",
   "metadata": {},
   "source": [
    "## Extracted csv files from all years in a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6d59f5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(file_names)):\n",
    "    extract_csv_from_zip(zip_downloads[i],file_names[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d3d4cd",
   "metadata": {},
   "source": [
    "## Key value pair to identify year of dataset {'year':'dataset'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "645088c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019\n"
     ]
    }
   ],
   "source": [
    "dic = {}\n",
    "year = int(extract_characters_before_zip(all_urls[-1]))\n",
    "print(year)\n",
    "temp = len(csv_files)\n",
    "# print(temp)\n",
    "\n",
    "\n",
    "while temp > 0:\n",
    "    dic[int(year)] = csv_files[temp-1]\n",
    "    temp -= 1\n",
    "    year += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "7cd0f0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(dic.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf04ae14",
   "metadata": {},
   "source": [
    "## Write datasets to control DB as tables for each year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "9e1db654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Hosted SQLServer DB instance\n",
    "# server = 'data-science.ck0dwzfc16xf.eu-west-1.rds.amazonaws.com'\n",
    "# database = ''\n",
    "# username = ''\n",
    "# password = ''\n",
    "\n",
    "# Connection parameters\n",
    "server_name = \"localhost\\MYSQL2019\" \n",
    "database_name = \"\"  \n",
    "username = \"\"  \n",
    "password = \"\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "1c384f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_string = f\"mssql+pyodbc://{username}:{password}@{server_name}/{database_name}?driver=ODBC+Driver+17+for+SQL+Server\"\n",
    "\n",
    "# Create an SQL Server engine\n",
    "engine = create_engine(connection_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "52cb0268",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from sqlalchemy.exc import SQLAlchemyError\n",
    "# try:\n",
    "#     # Try executing a simple query to test the connection\n",
    "#     result = engine.execute('SELECT 1')\n",
    "#     print(\"Connection successful!\")\n",
    "#     result.close()  # Close the result set\n",
    "# except SQLAlchemyError as e:\n",
    "#     print(\"Connection failed:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "1ca15cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019 survey dataset\n",
      "2020 survey dataset\n",
      "2021 survey dataset\n",
      "2022 survey dataset\n",
      "2023 survey dataset\n"
     ]
    }
   ],
   "source": [
    "# Write all year datasets to control DB while truncating column names that exceed the limit of 128 characters\n",
    "for k,v in dic.items():\n",
    "    new_columns = [col[:128] if len(col) > 128 else col for col in v.columns]\n",
    "    v.columns = new_columns\n",
    "    dtype_mapping = {col: String for col in v.select_dtypes(include=['object']).columns}\n",
    "    v.to_sql(\"dev_survey_\"+str(k), engine, if_exists='replace', index=False,dtype=dtype_mapping)\n",
    "    print(str(k)+\" survey dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8df6fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "current_year = datetime.now().year\n",
    "print(type(str(current_year)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
